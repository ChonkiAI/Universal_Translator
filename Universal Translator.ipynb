{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# YouTube Transcription Pipeline with Self-Hosted Whisper\n",
    "\n",
    "This notebook implements a pipeline that:\n",
    "1. Downloads audio from YouTube videos\n",
    "2. Uses locally hosted Whisper model for transcription and translation (no API costs)\n",
    "3. Converts the output to PDF\n",
    "\n",
    "## Setup and Requirements\n",
    "\n",
    "- Python 3.8+\n",
    "- FFmpeg (for audio processing)\n",
    "- Required packages: yt-dlp, openai-whisper, torch, fpdf\n",
    "- GPU recommended but not required (CPU will be slower)\n",
    "\n",
    "## Paste the Youtube video link in the last cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Install required packages in Jupyter Notebook\n",
    "# !pip install yt-dlp\n",
    "# !pip install -U openai-whisper\n",
    "# !pip install fpdf\n",
    "# !pip install torch  # Skip this if torch is already installed or if you're using GPU and need a specific version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Import required dependencies\n",
    "!pip install yt_dlp fpdf requests python-dotenv torch transformers openai-whisper tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import yt_dlp\n",
    "import whisper\n",
    "from fpdf import FPDF\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from IPython.display import FileLink, display, Markdown\n",
    "import subprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories if they don't exist\n",
    "os.makedirs(\"downloads\", exist_ok=True)\n",
    "os.makedirs(\"transcripts\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language dictionary loaded with 31 languages\n"
     ]
    }
   ],
   "source": [
    "# Language options dictionary (language code: language name)\n",
    "LANGUAGE_OPTIONS = {\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"de\": \"German\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"bn\": \"Bengali\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"vi\": \"Vietnamese\",\n",
    "    \"th\": \"Thai\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"ms\": \"Malay\",\n",
    "    \"fa\": \"Persian\",\n",
    "    \"he\": \"Hebrew\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"sv\": \"Swedish\",\n",
    "    \"da\": \"Danish\",\n",
    "    \"no\": \"Norwegian\",\n",
    "    \"fi\": \"Finnish\",\n",
    "    \"hu\": \"Hungarian\",\n",
    "    \"el\": \"Greek\",\n",
    "    \"ro\": \"Romanian\",\n",
    "    \"uk\": \"Ukrainian\"\n",
    "}\n",
    "\n",
    "print(\"Language dictionary loaded with\", len(LANGUAGE_OPTIONS), \"languages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Why not? Why not? Why not? Why not? I don't know. I don't know. Something else. Why not?\n",
      "\n",
      "Cleaned text:\n",
      "Why not? I don't know. Something else. Why not?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_repeated_phrases(text):\n",
    "    \"\"\"Clean up repeated phrases in the transcript text\n",
    "    \n",
    "    This function removes repetitive phrases like \"Why not? Why not? Why not?\"\n",
    "    that might appear in the transcript, making it more readable.\n",
    "    \"\"\"\n",
    "    # Common repeated phrases to look for\n",
    "    common_phrases = [\n",
    "        \"Why not?\", \n",
    "        \"I don't know.\", \n",
    "        \"I love you.\", \n",
    "        \"I'm not sure.\",\n",
    "        \"What is that?\", \n",
    "        \"I like you.\", \n",
    "        \"I'm a big fan of this movie.\",\n",
    "        \"You are so smart.\"\n",
    "    ]\n",
    "    \n",
    "    cleaned_text = text\n",
    "    \n",
    "    # Clean up common repeated phrases\n",
    "    for phrase in common_phrases:\n",
    "        # Replace 3+ consecutive occurrences with just one\n",
    "        pattern = f\"({re.escape(phrase)}\\\\s*){{3,}}\"\n",
    "        cleaned_text = re.sub(pattern, phrase + \" \", cleaned_text)\n",
    "        \n",
    "        # Replace 2 consecutive occurrences with just one\n",
    "        pattern = f\"({re.escape(phrase)}\\\\s*){{2}}\"\n",
    "        cleaned_text = re.sub(pattern, phrase + \" \", cleaned_text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Test the function with a sample text\n",
    "sample_text = \"Why not? Why not? Why not? Why not? I don't know. I don't know. Something else. Why not?\"\n",
    "print(\"Original text:\")\n",
    "print(sample_text)\n",
    "print(\"\\nCleaned text:\")\n",
    "print(clean_repeated_phrases(sample_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define TranscriptionPipeline Class\n",
    "\n",
    "Now we'll implement the main pipeline class with methods for downloading, transcribing, and creating PDFs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified TranscriptionPipeline Class\n",
    "class TranscriptionPipeline:\n",
    "    def __init__(self, whisper_model=None, model_size=\"small\"):  # Added model_size parameter\n",
    "        \"\"\"Initialize the transcription pipeline with local Whisper model\"\"\"\n",
    "        self.whisper_model = whisper_model or model  # Use the globally loaded model\n",
    "        self.model_size = model_size # Store the model size\n",
    "\n",
    "        # Create output directories if they don't exist\n",
    "        os.makedirs(\"downloads\", exist_ok=True)\n",
    "        os.makedirs(\"transcripts\", exist_ok=True)\n",
    "\n",
    "    def remove_consecutive_duplicates(self, text):\n",
    "        \"\"\"Remove consecutive duplicate lines from transcription text\"\"\"\n",
    "        if not text:\n",
    "            return text\n",
    "        lines = text.split('\\\\n')\n",
    "        if len(lines) <= 1:\n",
    "            return text\n",
    "\n",
    "        def extract_content(line):\n",
    "            parts = line.split(']  ')\n",
    "            return parts[1].strip() if len(parts) > 1 else line.strip()\n",
    "\n",
    "        result = [lines[0]]\n",
    "        for i in range(1, len(lines)):\n",
    "            current_content = extract_content(lines[i])\n",
    "            prev_content = extract_content(result[-1])\n",
    "            if current_content != prev_content or not current_content:\n",
    "                result.append(lines[i])\n",
    "        return '\\\\n'.join(result)\n",
    "\n",
    "    def download_audio(self, youtube_url):\n",
    "        \"\"\"Download audio from a YouTube video\"\"\"\n",
    "        print(f\"Downloading audio from: {youtube_url}\")\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': 'downloads/%(title)s.%(ext)s',\n",
    "            'restrictfilenames': True,\n",
    "            'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}],\n",
    "        }\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(youtube_url, download=True)\n",
    "            # yt-dlp sanitizes the title, we get the final path from the info dict\n",
    "            audio_file = ydl.prepare_filename(info).replace('.webm', '.mp3').replace('.m4a', '.mp3')\n",
    "            print(f\"Audio downloaded: {audio_file}\")\n",
    "            \n",
    "            # Get and print video length\n",
    "            duration = info.get('duration')\n",
    "            if duration:\n",
    "                minutes = int(duration / 60)\n",
    "                seconds = int(duration % 60)\n",
    "                print(f\"Video length: {minutes} minutes {seconds} seconds\")\n",
    "            \n",
    "            return audio_file, info['title'], duration # Return duration as well\n",
    "\n",
    "    def extract_audio_from_video(self, video_path):\n",
    "        \"\"\"Extracts audio from a local video file using ffmpeg.\"\"\"\n",
    "        print(f\"Extracting audio from: {video_path}\")\n",
    "        if not Path(video_path).exists():\n",
    "            raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "\n",
    "        video_title = Path(video_path).stem\n",
    "        audio_file_path = f\"downloads/{video_title}.mp3\"\n",
    "\n",
    "        # Command to extract audio using ffmpeg, overwriting if exists (-y)\n",
    "        command = f'ffmpeg -i \\\"{video_path}\\\" -y -vn -acodec mp3 -ab 192k \\\"{audio_file_path}\\\"'\n",
    "        \n",
    "        print(f\"Running FFmpeg to extract audio...\")\n",
    "        try:\n",
    "            result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)\n",
    "            print(f\"Audio extracted successfully: {audio_file_path}\")\n",
    "\n",
    "            # Get video length using ffprobe\n",
    "            duration_command = f'ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \\\"{video_path}\\\"'\n",
    "            duration_output = subprocess.check_output(duration_command, shell=True, text=True)\n",
    "            duration = float(duration_output.strip())\n",
    "            \n",
    "            if duration:\n",
    "                minutes = int(duration / 60)\n",
    "                seconds = int(duration % 60)\n",
    "                print(f\"Video length: {minutes} minutes {seconds} seconds\")\n",
    "\n",
    "            return audio_file_path, video_title, duration # Return duration\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error during FFmpeg execution: {e.stderr}\")\n",
    "            raise RuntimeError(f\"Failed to extract audio from {video_path}\")\n",
    "\n",
    "    def get_audio_length(self, audio_file_path):\n",
    "        \"\"\"Gets the length of an audio file using ffprobe.\"\"\"\n",
    "        try:\n",
    "            command = f'ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \\\"{audio_file_path}\\\"'\n",
    "            duration_output = subprocess.check_output(command, shell=True, text=True)\n",
    "            duration = float(duration_output.strip())\n",
    "            \n",
    "            if duration:\n",
    "                minutes = int(duration / 60)\n",
    "                seconds = int(duration % 60)\n",
    "                print(f\"Audio length: {minutes} minutes {seconds} seconds\")\n",
    "            return duration\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error getting audio length with ffprobe: {e.stderr}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    def detect_language(self, audio_file):\n",
    "        \"\"\"Detect the language of the audio file\"\"\"\n",
    "        print(\"Detecting original language...\")\n",
    "        if not os.path.exists(audio_file):\n",
    "            raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "        \n",
    "        audio = whisper.load_audio(audio_file)\n",
    "        audio = whisper.pad_or_trim(audio)\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(self.whisper_model.device)\n",
    "        _, probs = self.whisper_model.detect_language(mel)\n",
    "        detected_lang = max(probs, key=probs.get)\n",
    "        lang_name = LANGUAGE_OPTIONS.get(detected_lang, \"Unknown\")\n",
    "        print(f\"Detected language: {detected_lang} ({lang_name}) - confidence: {probs[detected_lang]:.2f}\")\n",
    "        return detected_lang, probs[detected_lang]\n",
    "\n",
    "    def transcribe_audio(self, audio_file, target_language):\n",
    "        \"\"\"Transcribe and/or translate audio using local Whisper model\"\"\"\n",
    "        print(f\"Transcribing audio to {target_language}...\")\n",
    "        if not os.path.exists(audio_file):\n",
    "            raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "\n",
    "        detected_lang, confidence = self.detect_language(audio_file)\n",
    "        \n",
    "        task = \"translate\" if target_language != detected_lang and target_language == 'en' else \"transcribe\"\n",
    "        print(f\"Performing task: {task} to language: {target_language}\")\n",
    "\n",
    "        result = self.whisper_model.transcribe(\n",
    "            audio_file,\n",
    "            task=task,\n",
    "            language=target_language if task == \"transcribe\" else None, # Specify language for transcription, not for translation\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        cleaned_text = self.remove_consecutive_duplicates(result[\"text\"])\n",
    "        result_with_lang = {\n",
    "            \"text\": cleaned_text,\n",
    "            \"detected_language\": detected_lang,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "        return result_with_lang\n",
    "\n",
    "    def create_pdf(self, transcript_result, title, target_language, output_file=None):\n",
    "        \"\"\"Generate PDF from transcription text\"\"\"\n",
    "        text = clean_repeated_phrases(transcript_result[\"text\"])\n",
    "        detected_lang = transcript_result[\"detected_language\"]\n",
    "        \n",
    "        # Incorporate model size into the safe title for the filename\n",
    "        safe_title = \"\".join([c if c.isalnum() else \"_\" for c in title])\n",
    "        \n",
    "        if output_file is None:\n",
    "            output_file = f\"transcripts/{safe_title}_{self.model_size}_{target_language}.pdf\" # Modified filename\n",
    "        \n",
    "        print(f\"Creating PDF: {output_file}\")\n",
    "        source_lang_name = LANGUAGE_OPTIONS.get(detected_lang, \"Unknown\")\n",
    "        target_lang_name = LANGUAGE_OPTIONS.get(target_language, \"Unknown\")\n",
    "\n",
    "        try:\n",
    "            clean_text = text.encode('latin-1', 'replace').decode('latin-1')\n",
    "            pdf = FPDF()\n",
    "            pdf.add_page()\n",
    "            pdf.set_auto_page_break(auto=True, margin=15)\n",
    "            \n",
    "            # Add Title\n",
    "            pdf.set_font(\"Arial\", \"B\", 16)\n",
    "            pdf.multi_cell(0, 10, f\"Transcript: {title}\", align=\"C\")\n",
    "            pdf.ln(10)\n",
    "            \n",
    "            # Add language info\n",
    "            pdf.set_font(\"Arial\", \"I\", 12)\n",
    "            pdf.cell(0, 10, f\"Original language: {detected_lang} ({source_lang_name})\", ln=True)\n",
    "            pdf.cell(0, 10, f\"Output language: {target_language} ({target_lang_name})\", ln=True)\n",
    "            pdf.cell(0, 10, f\"Whisper Model: {self.model_size}\", ln=True) # Add model info\n",
    "            pdf.ln(5)\n",
    "            \n",
    "            # Add transcript text\n",
    "            pdf.set_font(\"Arial\", \"\", 12)\n",
    "            pdf.multi_cell(0, 10, clean_text)\n",
    "            \n",
    "            pdf.output(output_file)\n",
    "            return output_file\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating PDF: {e}\")\n",
    "            txt_file = output_file.replace(\".pdf\", \".txt\")\n",
    "            print(f\"Saving as text file instead: {txt_file}\")\n",
    "            with open(txt_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"Transcript: {title}\\\\n\\\\n\")\n",
    "                f.write(f\"Original language: {detected_lang} ({source_lang_name})\\\\n\")\n",
    "                f.write(f\"Output language: {target_language} ({target_lang_name})\\\\n\\\\n\")\n",
    "                f.write(f\"Whisper Model: {self.model_size}\\\\n\\\\n\") # Add model info to TXT\n",
    "                f.write(text)\n",
    "            return txt_file\n",
    "\n",
    "    def process_media(self, input_path, target_language):\n",
    "        \"\"\"\n",
    "        Process a media input: download or extract audio, transcribe, and create a PDF.\n",
    "        The input can be a YouTube URL, a local video file, or a local audio file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            title = \"\"\n",
    "            audio_file = \"\"\n",
    "            duration = None # Initialize duration\n",
    "\n",
    "            # Step 1: Get audio file and title based on input type\n",
    "            print(\"Step 1/3: Processing media input...\")\n",
    "            is_url = input_path.startswith(('http:', 'https:'))\n",
    "            is_video = any(input_path.lower().endswith(ext) for ext in ['.mp4', '.mkv', '.avi', '.mov', '.webm'])\n",
    "            is_audio = any(input_path.lower().endswith(ext) for ext in ['.mp3', '.wav', '.m4a', '.flac'])\n",
    "\n",
    "            if is_url:\n",
    "                audio_file, title, duration = self.download_audio(input_path) # Get duration\n",
    "            elif is_video:\n",
    "                audio_file, title, duration = self.extract_audio_from_video(input_path) # Get duration\n",
    "            elif is_audio:\n",
    "                audio_file = input_path\n",
    "                title = Path(input_path).stem\n",
    "                print(f\"Using local audio file: {audio_file}\")\n",
    "                duration = self.get_audio_length(audio_file) # Get duration for audio file\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported input type. Please provide a YouTube URL, video file, or audio file.\")\n",
    "\n",
    "            # Step 2: Transcribe and translate audio\n",
    "            print(\"\\nStep 2/3: Transcribing audio...\")\n",
    "            transcript_result = self.transcribe_audio(audio_file, target_language)\n",
    "            \n",
    "            # Step 3: Create PDF\n",
    "            print(\"\\nStep 3/3: Creating PDF...\")\n",
    "            pdf_file = self.create_pdf(transcript_result, title, target_language)\n",
    "            \n",
    "            # Final summary\n",
    "            detected_lang = transcript_result[\"detected_language\"]\n",
    "            source_lang_name = LANGUAGE_OPTIONS.get(detected_lang, \"Unknown\")\n",
    "            target_lang_name = LANGUAGE_OPTIONS.get(target_language, \"Unknown\")\n",
    "            \n",
    "            print(f\"\\nVideo language: {detected_lang} ({source_lang_name})\")\n",
    "            print(f\"Output language: {target_language} ({target_lang_name})\")\n",
    "            print(f\"Process completed successfully! PDF saved at: {pdf_file}\")\n",
    "            \n",
    "            return pdf_file\n",
    "        except Exception as e:\n",
    "            print(f\"Error in pipeline: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Whisper Model Size\n",
    "\n",
    "Choose the Whisper model size to use for transcription. Larger models are more accurate but require more memory and computational resources:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Selected model: small\n",
      "Model parameters: 244M\n",
      "Approx. required VRAM: ~2 GB\n",
      "\n",
      "Loading Whisper model 'small'...\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Select Whisper model size\n",
    "# Available models: \"tiny\", \"base\", \"small\", \"medium\", \"large\"\n",
    "# Larger models are more accurate but require more memory and compute\n",
    "# Recommendation: Start with \"base\" or \"small\" for a balance of speed and accuracy\n",
    "WHISPER_MODEL_SIZE = \"small\"  # Change this to your desired model size\n",
    "\n",
    "# Print available devices for running the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Display model size info\n",
    "model_sizes = {\n",
    "    \"tiny\": {\"parameters\": \"39M\", \"required_vram\": \"~1 GB\", \"english_only\": False},\n",
    "    \"base\": {\"parameters\": \"74M\", \"required_vram\": \"~1 GB\", \"english_only\": False},\n",
    "    \"small\": {\"parameters\": \"244M\", \"required_vram\": \"~2 GB\", \"english_only\": False},\n",
    "    \"medium\": {\"parameters\": \"769M\", \"required_vram\": \"~5 GB\", \"english_only\": False},\n",
    "    \"large\": {\"parameters\": \"1550M\", \"required_vram\": \"~10 GB\", \"english_only\": False},\n",
    "}\n",
    "\n",
    "print(f\"\\nSelected model: {WHISPER_MODEL_SIZE}\")\n",
    "print(f\"Model parameters: {model_sizes[WHISPER_MODEL_SIZE]['parameters']}\")\n",
    "print(f\"Approx. required VRAM: {model_sizes[WHISPER_MODEL_SIZE]['required_vram']}\")\n",
    "\n",
    "# Check if selected model is reasonable for your device\n",
    "if device == \"cpu\" and WHISPER_MODEL_SIZE in [\"medium\", \"large\"]:\n",
    "    print(\"\\nWARNING: You've selected a large model to run on CPU. This may be very slow.\")\n",
    "    print(\"Consider using a smaller model like 'base' or 'small' for better performance on CPU.\")\n",
    "\n",
    "# Load the model (this will download the model first time)\n",
    "print(f\"\\nLoading Whisper model '{WHISPER_MODEL_SIZE}'...\")\n",
    "model = whisper.load_model(WHISPER_MODEL_SIZE, device=device)\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run the Pipeline\n",
    "\n",
    "Now let's use our pipeline class to process a YouTube video:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated Feature: Support for Python version 3.8 has been deprecated. Please update to Python 3.9 or above\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting transcription pipeline for: https://www.youtube.com/watch?v=3dKSBfRMmdU&t=39s\n",
      "Target language: en (English)\n",
      "Step 1/3: Processing media input...\n",
      "Downloading audio from: https://www.youtube.com/watch?v=3dKSBfRMmdU&t=39s\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=3dKSBfRMmdU&t=39s\n",
      "[youtube] 3dKSBfRMmdU: Downloading webpage\n",
      "[youtube] 3dKSBfRMmdU: Downloading ios player API JSON\n",
      "[youtube] 3dKSBfRMmdU: Downloading mweb player API JSON\n",
      "[youtube] 3dKSBfRMmdU: Downloading player 5dcb2c1f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/5dcb2c1f/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] 3dKSBfRMmdU: nsig extraction failed: Some formats may be missing\n",
      "         n = RA1tnfURajH6JVhvFhTlj ; player = https://www.youtube.com/s/player/5dcb2c1f/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/5dcb2c1f/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] 3dKSBfRMmdU: nsig extraction failed: Some formats may be missing\n",
      "         n = HYOWVmMB2L_VwmTkp7R3X ; player = https://www.youtube.com/s/player/5dcb2c1f/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 3dKSBfRMmdU: Downloading m3u8 information\n",
      "[info] 3dKSBfRMmdU: Downloading 1 format(s): 251\n",
      "[download] Destination: downloads\\MOST_CRINGE_FEED_EVARIDI_FIRST_VIDEO_II_KAKARAKAYTALKS.webm\n",
      "[download] 100% of   12.63MiB in 00:00:05 at 2.44MiB/s   \n",
      "[ExtractAudio] Destination: downloads\\MOST_CRINGE_FEED_EVARIDI_FIRST_VIDEO_II_KAKARAKAYTALKS.mp3\n",
      "Deleting original file downloads\\MOST_CRINGE_FEED_EVARIDI_FIRST_VIDEO_II_KAKARAKAYTALKS.webm (pass -k to keep)\n",
      "Audio downloaded: downloads\\MOST_CRINGE_FEED_EVARIDI_FIRST_VIDEO_II_KAKARAKAYTALKS.mp3\n",
      "Video length: 14 minutes 8 seconds\n",
      "\n",
      "Step 2/3: Transcribing audio...\n",
      "Transcribing audio to en...\n",
      "Detecting original language...\n",
      "Detected language: te (Unknown) - confidence: 0.97\n",
      "Performing task: translate to language: en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
      "Detected language: Telugu\n",
      "[00:00.000 --> 00:01.240]  who are you?\n",
      "[00:06.040 --> 00:13.200]  Hey kid do not listen to him I will later tell you\n",
      "[00:15.800 --> 00:17.320]  Am I looking so ugly?\n",
      "[00:19.140 --> 00:20.020]  Do not even look like a lady\n",
      "[00:20.020 --> 00:23.620]  Why are you explaining all these strange things in the first video?\n",
      "[00:23.620 --> 00:24.620]  Why not?\n",
      "[00:24.620 --> 00:26.120]  Why not strangers?\n",
      "[00:26.120 --> 00:30.620]  How much I can see, how much I can hold on to, dreams.\n",
      "[00:30.620 --> 00:32.120]  Yeah, dreams.\n",
      "[00:32.120 --> 00:32.620]  Yeah.\n",
      "[00:32.620 --> 00:33.620]  What did you say Kalam?\n",
      "[00:33.620 --> 00:34.420]  Kalam?\n",
      "[00:34.420 --> 00:35.420]  Kalam said, dreams.\n",
      "[00:35.420 --> 00:36.120]  Stories.\n",
      "[00:36.120 --> 00:36.620]  Hmm?\n",
      "[00:36.620 --> 00:37.120]  Hmm.\n",
      "[00:37.120 --> 00:38.420]  When Kalam said dreams...\n",
      "[00:38.420 --> 00:40.220]  I should have cut you then.\n",
      "[00:40.220 --> 00:41.220]  I did a mistake.\n",
      "[00:41.220 --> 00:42.220]  Okay, I'll see.\n",
      "[00:42.220 --> 00:42.720]  Guru!\n",
      "[00:42.720 --> 00:43.220]  I'll see.\n",
      "[00:43.220 --> 00:43.720]  Guru!\n",
      "[00:43.720 --> 00:46.220]  Anyways, so my first YouTube video...\n",
      "[00:46.220 --> 00:50.620]  I wanted to do a concept like this and discuss it with my friends.\n",
      "[00:50.620 --> 00:54.620]  I thought about it and thought about it.\n",
      "[00:54.620 --> 00:56.620]  Finally, we thought of a video.\n",
      "[00:56.620 --> 00:59.120]  That is, Roshan Genji.\n",
      "[00:59.120 --> 01:01.120]  Roshan Genji?\n",
      "[01:01.120 --> 01:02.620]  Did you hear that?\n",
      "[01:02.620 --> 01:04.020]  Hey, uncle.\n",
      "[01:04.020 --> 01:05.120]  What uncle?\n",
      "[01:05.120 --> 01:07.620]  You didn't do comedy games with me, right?\n",
      "[01:07.620 --> 01:08.620]  No.\n",
      "[01:08.620 --> 01:12.620]  Basically, I used to take the video as a key reset.\n",
      "[01:12.620 --> 01:15.120]  I posted it on my Instagram.\n",
      "[01:15.520 --> 01:20.520]  After I shared it with my dad, I shared it with my dad for 6 years.\n",
      "[01:20.520 --> 01:22.020]  It's okay if we are destroyed.\n",
      "[01:22.020 --> 01:23.220]  We shouldn't be left behind.\n",
      "[01:23.220 --> 01:24.920]  That's our Indian psychology.\n",
      "[01:24.920 --> 01:29.220]  I know God who is my God who has hit many naughty girls.\n",
      "[01:29.220 --> 01:30.720]  He is a fool.\n",
      "[01:30.720 --> 01:33.820]  Not all that, but you shared my feed.\n",
      "[01:33.820 --> 01:35.220]  I shared your feed.\n",
      "[01:35.220 --> 01:36.520]  What are you going to do now?\n",
      "[01:36.520 --> 01:40.520]  Don't ever say, what I'm going to do in life.\n",
      "[01:41.520 --> 01:45.520]  You have a clarity.\n",
      "[01:45.520 --> 01:48.120]  We are not going to discuss it.\n",
      "[01:48.120 --> 01:50.120]  We are going to go to any video.\n",
      "[01:50.120 --> 01:51.120]  Keep it all, sir.\n",
      "[01:51.120 --> 01:52.620]  This is Roshan Genji.\n",
      "[01:52.620 --> 01:54.620]  We are going to share a feed with someone.\n",
      "[01:54.620 --> 01:59.620]  We will rate the number of cringes in that feed.\n",
      "[01:59.620 --> 02:04.620]  We will give a name board to those cringes.\n",
      "[02:04.620 --> 02:06.620]  We will write a paper on it and put it in the photo.\n",
      "[02:06.620 --> 02:08.120]  Stick it once.\n",
      "[02:08.220 --> 02:10.220]  We will give a point to those cringes.\n",
      "[02:10.220 --> 02:12.220]  There is nothing to judge.\n",
      "[02:12.220 --> 02:14.220]  We will only make them cringe.\n",
      "[02:14.220 --> 02:16.220]  If they are in Instagram, they will be cringe.\n",
      "[02:16.220 --> 02:18.220]  Or they will be in Dasan.\n",
      "[02:18.220 --> 02:20.220]  They will not do anything to you.\n",
      "[02:20.220 --> 02:22.220]  I will tell you something.\n",
      "[02:22.220 --> 02:24.220]  Let's see.\n",
      "[02:24.220 --> 02:26.220]  Let's see who will be the cringe.\n",
      "[02:38.220 --> 02:40.220]  It's starting.\n",
      "[02:40.220 --> 02:42.220]  It's starting.\n",
      "[02:42.220 --> 02:43.220]  What?\n",
      "[02:43.220 --> 02:45.220]  What is the meaning of that?\n",
      "[02:45.220 --> 02:46.220]  Sit down.\n",
      "[02:46.220 --> 02:48.220]  Don't make me cringe.\n",
      "[02:48.220 --> 02:50.220]  Bro, I'm not going to do anything.\n",
      "[02:50.220 --> 02:52.220]  I'm not going to do anything.\n",
      "[02:52.220 --> 02:54.220]  I'm not going to do anything.\n",
      "[02:54.220 --> 02:56.220]  You can earn yourself.\n",
      "[02:56.220 --> 02:58.220]  I know that.\n",
      "[02:58.220 --> 03:00.220]  Yeah.\n",
      "[03:00.220 --> 03:02.220]  Cringe.\n",
      "[03:02.220 --> 03:04.220]  Cringe rating.\n",
      "[03:04.320 --> 03:06.320]  I'm not going to do anything.\n",
      "[03:06.320 --> 03:08.320]  I'm going to do 8.5.\n",
      "[03:08.320 --> 03:10.320]  I'm not going to do anything.\n",
      "[03:10.320 --> 03:12.320]  I'm not going to do anything.\n",
      "[03:12.320 --> 03:14.320]  Why are you making me do something?\n",
      "[03:14.320 --> 03:16.320]  Why are you making me do something?\n",
      "[03:34.420 --> 03:36.420]  I'm making it.\n",
      "[03:41.780 --> 03:43.780]  Is this cheating?\n",
      "[03:43.780 --> 03:44.820]  No!\n",
      "[03:46.180 --> 03:48.200]  Okay.\n",
      "[03:48.200 --> 03:50.200]  What about the witch?\n",
      "[03:50.440 --> 03:52.360]  Don't advantage them.\n",
      "[03:52.660 --> 03:53.660]  I don't know who they are.\n",
      "[03:53.660 --> 03:54.660]  Okay.\n",
      "[03:54.660 --> 03:55.660]  What about you?\n",
      "[03:55.660 --> 03:56.660]  Let's see.\n",
      "[03:56.660 --> 03:57.320]  Oh f**k, rough plz\n",
      "[04:03.200 --> 04:05.520]  This气, isurning\n",
      "[04:24.040 --> 04:25.280]  OId my daughter\n",
      "[04:25.280 --> 04:27.280]  I am not sure if it is IHG\n",
      "[04:27.280 --> 04:29.280]  Capital A\n",
      "[04:29.280 --> 04:31.280]  Small w\n",
      "[04:31.280 --> 04:33.280]  Capital w\n",
      "[04:33.280 --> 04:35.280]  Small w\n",
      "[04:35.280 --> 04:37.280]  Small w\n",
      "[04:37.280 --> 04:39.280]  Capital w\n",
      "[04:39.280 --> 04:41.280]  Small w\n",
      "[04:41.280 --> 04:43.280]  Small w\n",
      "[04:43.280 --> 04:45.280]  I wrote it and wrote it\n",
      "[04:45.280 --> 04:47.280]  I wrote it and wrote it\n",
      "[04:47.280 --> 04:49.280]  I wrote it and wrote it\n",
      "[04:49.280 --> 04:51.280]  What are you doing?\n",
      "[04:51.280 --> 04:53.280]  Hey, show it to someone\n",
      "[04:53.280 --> 04:55.280]  Leave it, it is not good\n",
      "[04:55.280 --> 04:57.280]  Tell me, leave it\n",
      "[05:13.280 --> 05:15.280]  Hey, what is that?\n",
      "[05:15.280 --> 05:17.280]  I don't know sir\n",
      "[05:19.280 --> 05:21.280]  What is that?\n",
      "[05:21.280 --> 05:23.280]  What is this?\n",
      "[05:25.280 --> 05:27.280]  It is a concept\n",
      "[05:27.280 --> 05:29.280]  Children are not educated\n",
      "[05:29.280 --> 05:31.280]  They are doing their job\n",
      "[05:31.280 --> 05:33.280]  If they give a good haul\n",
      "[05:33.280 --> 05:35.280]  They will give a good look\n",
      "[05:35.280 --> 05:37.280]  They are doing their job\n",
      "[05:37.280 --> 05:39.280]  What are they doing?\n",
      "[05:39.280 --> 05:41.280]  Beauty camera\n",
      "[05:41.280 --> 05:43.280]  They are taking a video like a beauty mat\n",
      "[05:43.280 --> 05:45.280]  It is not good, generation is bad\n",
      "[05:45.280 --> 05:47.280]  Hey, show it to someone\n",
      "[05:47.280 --> 05:49.280]  What is this?\n",
      "[05:49.280 --> 05:51.280]  What are you saying?\n",
      "[05:55.280 --> 05:57.280]  Children\n",
      "[05:57.280 --> 05:59.280]  Enjoy it, I will go to school\n",
      "[05:59.280 --> 06:01.280]  Mummy will eat lunch\n",
      "[06:01.280 --> 06:03.280]  You are right\n",
      "[06:03.280 --> 06:05.280]  Come, let's go to school\n",
      "[06:05.280 --> 06:07.280]  You go\n",
      "[06:07.280 --> 06:09.280]  He is coming\n",
      "[06:09.280 --> 06:11.280]  I can't drive\n",
      "[06:11.280 --> 06:13.280]  I can't do anything\n",
      "[06:13.280 --> 06:15.280]  I am tired\n",
      "[06:15.280 --> 06:17.280]  He is calling\n",
      "[06:17.280 --> 06:19.280]  He is coming\n",
      "[06:19.280 --> 06:21.280]  He is coming for a break\n",
      "[06:23.280 --> 06:25.280]  First, study\n",
      "[06:39.280 --> 06:41.280]  I don't know the meaning\n",
      "[06:41.280 --> 06:43.280]  But, it is a myth\n",
      "[06:43.280 --> 06:45.280]  We should do it again\n",
      "[06:45.280 --> 06:47.280]  First, we should do it again\n",
      "[06:47.280 --> 06:49.280]  I don't know the meaning\n",
      "[06:49.280 --> 06:51.280]  What is this?\n",
      "[06:51.280 --> 06:53.280]  Do you want to do it again?\n",
      "[06:59.280 --> 07:01.280]  I don't know\n",
      "[07:03.280 --> 07:05.280]  You go\n",
      "[07:05.280 --> 07:07.280]  He is calling me\n",
      "[07:07.280 --> 07:09.280]  You go\n",
      "[07:15.280 --> 07:17.280]  You go\n",
      "[07:23.280 --> 07:25.280]  He is calling me\n",
      "[07:25.280 --> 07:27.280]  Children\n",
      "[07:27.280 --> 07:29.280]  Children are not there\n",
      "[07:29.280 --> 07:31.280]  We are\n",
      "[07:31.280 --> 07:33.280]  We are\n",
      "[07:33.280 --> 07:35.280]  We should be\n",
      "[07:35.280 --> 07:37.280]  We should be\n",
      "[07:37.280 --> 07:39.280]  We should give the next student\n",
      "[07:39.280 --> 07:41.280]  She is not even a cringe\n",
      "[07:41.280 --> 07:43.280]  She is a snake\n",
      "[07:43.280 --> 07:45.280]  She is not even a cringe\n",
      "[07:45.280 --> 07:47.280]  She is not even a cringe\n",
      "[07:47.280 --> 07:49.280]  You said\n",
      "[07:49.280 --> 07:51.280]  I love you\n",
      "[07:51.280 --> 07:53.280]  You said\n",
      "[07:53.280 --> 07:55.280]  I love you\n",
      "[07:55.280 --> 07:57.280]  You don't know what you said\n",
      "[07:57.280 --> 07:59.280]  You are my son\n",
      "[07:59.280 --> 08:01.280]  I am your son\n",
      "[08:05.280 --> 08:07.280]  He is not there\n",
      "[08:07.280 --> 08:09.280]  He is the guy who is in front of the camera\n",
      "[08:09.280 --> 08:11.280]  9.55\n",
      "[08:13.280 --> 08:15.280]  He is not there\n",
      "[08:19.280 --> 08:21.280]  He is not there\n",
      "[08:21.280 --> 08:23.280]  He is in front of the camera\n",
      "[08:23.280 --> 08:25.280]  He is not there\n",
      "[08:25.280 --> 08:27.280]  He is in front of the camera\n",
      "[08:27.280 --> 08:29.280]  He is not there\n",
      "[08:31.280 --> 08:33.280]  We have reached a place\n",
      "[08:33.280 --> 08:35.280]  We should meet him\n",
      "[08:37.280 --> 08:39.280]  We should meet him\n",
      "[08:39.280 --> 08:41.280]  We will show you\n",
      "[08:41.280 --> 08:43.280]  the place\n",
      "[08:43.280 --> 08:45.280]  where he is\n",
      "[08:45.280 --> 08:47.280]  Oh my\n",
      "[08:47.280 --> 08:49.280]  What happened?\n",
      "[08:49.280 --> 08:51.280]  Why are you coming here?\n",
      "[08:51.280 --> 08:53.280]  What is that?\n",
      "[08:53.280 --> 08:55.280]  Why are you coming here?\n",
      "[08:55.280 --> 08:57.280]  Look at the base\n",
      "[08:57.280 --> 08:59.280]  What is that?\n",
      "[08:59.280 --> 09:01.280]  What is that?\n",
      "[09:01.280 --> 09:03.280]  What is that?\n",
      "[09:03.280 --> 09:05.280]  What is that?\n",
      "[09:05.280 --> 09:07.280]  What happened?\n",
      "[09:07.280 --> 09:09.280]  What?\n",
      "[09:09.280 --> 09:11.280]  What?\n",
      "[09:11.280 --> 09:13.280]  What is that?\n",
      "[09:13.280 --> 09:15.280]  What is that?\n",
      "[09:15.280 --> 09:17.280]  Please go home\n",
      "[09:17.280 --> 09:19.280]  I am not like that\n",
      "[09:19.280 --> 09:21.280]  I will not go home\n",
      "[09:21.280 --> 09:23.280]  I will not go home\n",
      "[09:23.280 --> 09:25.280]  What is the sun doing for the light?\n",
      "[09:25.280 --> 09:27.280]  What is the sun doing for you?\n",
      "[09:27.280 --> 09:29.280]  Go\n",
      "[09:29.280 --> 09:31.280]  Go\n",
      "[09:31.280 --> 09:33.280]  How can a person go home?\n",
      "[09:33.280 --> 09:35.280]  Go home\n",
      "[09:37.280 --> 09:39.280]  If it is for the young people\n",
      "[09:39.280 --> 09:41.280]  I am laughing for you\n",
      "[09:41.280 --> 09:43.280]  If it is for the young people\n",
      "[09:43.280 --> 09:45.280]  I am born for you\n",
      "[09:47.280 --> 09:49.280]  If it is for the sun\n",
      "[09:49.280 --> 09:51.280]  I am...\n",
      "[09:51.280 --> 09:53.280]  He is not a cringe\n",
      "[09:53.280 --> 09:55.280]  He is not a cringe\n",
      "[09:55.280 --> 09:57.280]  He is a cringe writing\n",
      "[09:57.280 --> 09:59.280]  Let us go and write\n",
      "[09:59.280 --> 10:01.280]  I saw him\n",
      "[10:01.280 --> 10:03.280]  I saw him\n",
      "[10:03.280 --> 10:05.280]  I saw him\n",
      "[10:05.280 --> 10:07.280]  What?\n",
      "[10:09.280 --> 10:11.280]  Now we will go to your field\n",
      "[10:11.280 --> 10:13.280]  In my field\n",
      "[10:13.280 --> 10:15.280]  There will be a pub\n",
      "[10:15.280 --> 10:17.280]  If not\n",
      "[10:17.280 --> 10:19.280]  Come\n",
      "[10:19.280 --> 10:21.280]  Come\n",
      "[10:21.280 --> 10:23.280]  What is wrong in that?\n",
      "[10:29.280 --> 10:31.280]  It is time\n",
      "[10:31.280 --> 10:33.280]  He is asking me to kill\n",
      "[10:33.280 --> 10:35.280]  Who is he?\n",
      "[10:41.280 --> 10:43.280]  Ratna\n",
      "[10:43.280 --> 10:45.280]  Why did she live?\n",
      "[10:45.280 --> 10:47.280]  Why did she kill her husband?\n",
      "[10:47.280 --> 10:49.280]  Why did she kill her husband?\n",
      "[10:49.280 --> 10:51.280]  Why did she kill her husband?\n",
      "[10:51.280 --> 10:53.280]  I will not go home\n",
      "[10:53.280 --> 10:55.280]  I will not go home\n",
      "[10:55.280 --> 10:57.280]  Who is he?\n",
      "[10:57.280 --> 10:59.280]  Where is Riya?\n",
      "[10:59.280 --> 11:01.280]  Where is Riya?\n",
      "[11:01.280 --> 11:03.280]  Who is he?\n",
      "[11:03.280 --> 11:05.280]  Come and comment\n",
      "[11:07.280 --> 11:09.280]  Shit\n",
      "[11:09.280 --> 11:11.280]  It is very dark\n",
      "[11:17.280 --> 11:19.280]  I will give you the rating for this cringe\n",
      "[11:19.280 --> 11:21.280]  It is not cringe\n",
      "[11:21.280 --> 11:23.280]  It is not cringe\n",
      "[11:23.280 --> 11:25.280]  I am not feeling\n",
      "[11:25.280 --> 11:27.280]  I am not feeling well\n",
      "[11:27.280 --> 11:29.280]  I am feeling like this\n",
      "[11:29.280 --> 11:31.280]  Ok\n",
      "[11:31.280 --> 11:33.280]  Which one?\n",
      "[11:33.280 --> 11:35.280]  8\n",
      "[11:35.280 --> 11:37.280]  He is very angry\n",
      "[11:37.280 --> 11:39.280]  He changed\n",
      "[11:39.280 --> 11:41.280]  He is cringe\n",
      "[11:41.280 --> 11:43.280]  Where is Riya?\n",
      "[11:43.280 --> 11:45.280]  Who is Riya?\n",
      "[11:45.280 --> 11:47.280]  Who is Dommi?\n",
      "[11:47.280 --> 11:49.280]  He is cringe\n",
      "[11:49.280 --> 11:51.280]  Why is he cringe?\n",
      "[11:51.280 --> 11:53.280]  You are not cringe\n",
      "[11:53.280 --> 11:55.280]  Your feed is the same\n",
      "[11:55.280 --> 11:57.280]  Your feed is cringe\n",
      "[11:57.280 --> 11:59.280]  Your feed is cringe\n",
      "[11:59.280 --> 12:01.280]  How many movies are there?\n",
      "[12:01.280 --> 12:03.280]  How many movies are there?\n",
      "[12:03.280 --> 12:05.280]  I am a big fan of this movie\n",
      "[12:09.280 --> 12:11.280]  I remember that\n",
      "[12:11.280 --> 12:13.280]  I remember that\n",
      "[12:27.280 --> 12:29.280]  I am not feeling well\n",
      "[12:53.280 --> 12:55.280]  I didn't feel good\n",
      "[12:55.280 --> 12:57.280]  My child is still alive\n",
      "[12:57.280 --> 12:59.280]  I got his number\n",
      "[12:59.280 --> 13:01.280]  It is cringe\n",
      "[13:01.280 --> 13:03.280]  It is cringe\n",
      "[13:03.280 --> 13:05.280]  He is cringe\n",
      "[13:05.280 --> 13:07.280]  I will give you the rating\n",
      "[13:07.280 --> 13:09.280]  What is this?\n",
      "[13:09.280 --> 13:11.280]  What is this?\n",
      "[13:11.280 --> 13:13.280]  What is this?\n",
      "[13:13.280 --> 13:15.280]  What is this?\n",
      "[13:15.280 --> 13:17.280]  What is this?\n",
      "[13:17.280 --> 13:19.280]  What is this?\n",
      "[13:19.280 --> 13:21.280]  What is this?\n",
      "[13:25.280 --> 13:26.280]  Assam\n",
      "[13:26.280 --> 13:27.280]  Right answer\n",
      "[13:27.280 --> 13:28.280]  Goa\n",
      "[13:28.280 --> 13:29.280]  Right answer\n",
      "[13:29.280 --> 13:30.280]  Andal Pradesh\n",
      "[13:30.280 --> 13:31.280]  Right answer\n",
      "[13:32.280 --> 13:33.280]  B.R\n",
      "[13:33.280 --> 13:34.280]  Right answer\n",
      "[13:34.280 --> 13:35.280]  Yeah, he said B.R\n",
      "[13:35.280 --> 13:36.280]  B.R, right answer\n",
      "[13:36.280 --> 13:37.280]  A.R\n",
      "[13:37.280 --> 13:38.280]  A.R\n",
      "[13:39.280 --> 13:40.280]  A.R\n",
      "[13:40.280 --> 13:41.280]  I'll do it\n",
      "[13:45.280 --> 13:47.280]  Okay, we'll see in the next video\n",
      "[13:48.280 --> 13:50.280]  So, the most cringe is\n",
      "[13:50.280 --> 13:51.280]  Me\n",
      "[13:51.280 --> 13:52.280]  Me\n",
      "[13:52.280 --> 13:53.280]  Me\n",
      "[13:54.280 --> 13:56.280]  I want to reach\n",
      "[13:56.280 --> 13:59.280]  1 million likes\n",
      "[13:59.280 --> 14:00.280]  So please\n",
      "[14:00.280 --> 14:02.280]  Sarapakara\n",
      "[14:02.280 --> 14:03.280]  Sarapakara\n",
      "[14:03.280 --> 14:04.280]  Sarapakara\n",
      "[14:04.280 --> 14:05.280]  Sarapakara\n",
      "[14:05.280 --> 14:06.280]  Sarapakara\n",
      "[14:06.280 --> 14:07.280]  Sarapakara\n",
      "[14:07.280 --> 14:08.280]  Sarapakara\n",
      "\n",
      "Step 3/3: Creating PDF...\n",
      "Creating PDF: transcripts/MOST_CRINGE_FEED_EVARIDI_______FIRST_VIDEO_II_KAKARAKAYTALKS_small_en.pdf\n",
      "\n",
      "Video language: te (Unknown)\n",
      "Output language: en (English)\n",
      "Process completed successfully! PDF saved at: transcripts/MOST_CRINGE_FEED_EVARIDI_______FIRST_VIDEO_II_KAKARAKAYTALKS_small_en.pdf\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**PDF generated successfully!** [Open PDF](transcripts/MOST_CRINGE_FEED_EVARIDI_______FIRST_VIDEO_II_KAKARAKAYTALKS_small_en.pdf)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the transcription pipeline with the local Whisper model\n",
    "pipeline = TranscriptionPipeline(whisper_model=model, model_size=WHISPER_MODEL_SIZE)\n",
    "\n",
    "# --- CHOOSE YOUR INPUT METHOD ---\n",
    "\n",
    "# Option 1: YouTube URL\n",
    "#input_path = \"Youtube Video url\"\n",
    "\n",
    "# Option 2: Local Video File Path\n",
    "# Make sure to upload the video file to your notebook's environment or provide the full path.\n",
    "# input_path = \"path/to/your/video.mp4\" \n",
    "\n",
    "# Option 3: Local Audio File Path\n",
    "# Make sure the audio file is in a common format like MP3, WAV, M4A.\n",
    "# input_path = \"rihanna-diamonds.mp3\" # <-- CHANGE THIS to your file path or URL\n",
    "\n",
    "# Set the target language for the output\n",
    "target_language = \"en\"  # e.g., 'en', 'es', 'fr', 'de', 'ja'\n",
    "\n",
    "# --- Run the pipeline ---\n",
    "\n",
    "print(f\"Starting transcription pipeline for: {input_path}\")\n",
    "print(f\"Target language: {target_language} ({LANGUAGE_OPTIONS.get(target_language, 'Unknown')})\")\n",
    "\n",
    "pdf_path = pipeline.process_media(input_path, target_language)\n",
    "\n",
    "# Display a link to the generated PDF if the process was successful\n",
    "if pdf_path:\n",
    "    display(Markdown(f\"**PDF generated successfully!** [Open PDF]({pdf_path})\"))\n",
    "else:\n",
    "    display(Markdown(\"**Pipeline failed. Please check the error messages above.**\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Batch Processing Multiple Videos\n",
    "\n",
    "If you want to process multiple videos at once:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of YouTube URLs and their target languages\n",
    "# # Use our language options dictionary to select desired languages\n",
    "# videos_to_process = [\n",
    "#     {\"url\": \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\", \"language\": \"en\"},  # English\n",
    "#     {\"url\": \"https://www.youtube.com/watch?v=VIDEO_ID_2\", \"language\": \"es\"},   # Spanish\n",
    "#     # Add more videos as needed\n",
    "#     # You can use any language code from LANGUAGE_OPTIONS dictionary\n",
    "# ]\n",
    "\n",
    "# # Print available languages as a reminder\n",
    "# print(\"Available languages for batch processing:\")\n",
    "# print(\", \".join([f\"{code}: {name}\" for code, name in list(LANGUAGE_OPTIONS.items())[:10]]))\n",
    "# print(f\"... and {len(LANGUAGE_OPTIONS) - 10} more languages (see language options cell above)\")\n",
    "\n",
    "# # Process each video\n",
    "# results = []\n",
    "# for video in videos_to_process:\n",
    "#     print(f\"\\nProcessing video: {video['url']} in {video['language']}\")\n",
    "#     pdf_path = pipeline.process_video(video[\"url\"], video[\"language\"])\n",
    "#     results.append({\n",
    "#         \"url\": video[\"url\"],\n",
    "#         \"language\": video[\"language\"],\n",
    "#         \"success\": pdf_path is not None,\n",
    "#         \"pdf_path\": pdf_path\n",
    "#     })\n",
    "\n",
    "# # Display results\n",
    "# print(\"\\nProcessing Results:\")\n",
    "# for i, result in enumerate(results, 1):\n",
    "#     status = \"✅ Success\" if result[\"success\"] else \"❌ Failed\"\n",
    "#     print(f\"{i}. {status} - {result['url']} ({result['language']})\")\n",
    "#     if result[\"success\"]:\n",
    "#         print(f\"   PDF: {result['pdf_path']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
